# Graph Kernel Attention Transformers (GKAT)

This repo contains the implementation of the GKAT algorithm in the paper [From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers](http://arxiv.org/abs/2107.07999). 


![GKAT_description](https://github.com/HL-hanlin/GKAT/blob/main/img/gkat-figure-one.jpg)


